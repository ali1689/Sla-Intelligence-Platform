{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09bb150c-51ad-460c-a1ff-512ec61c321e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract selected Jira columns from CSV\n",
    "# Save into EXISTING slainte_bronze.jira_table\n",
    "# ============================================================\n",
    "import re\n",
    "from pyspark.sql import functions as F\n",
    "# -----------------------\n",
    "# CONFIG\n",
    "# -----------------------\n",
    "BRONZE_DB = \"slainte_bronze\"\n",
    "BRONZE_TABLE = \"jira_table\"\n",
    "file_path = \"/Volumes/workspace/slainte_bronze/vol/GFG_FINAL.csv\"\n",
    "desired_cols = [\n",
    "   \"Summary\",\"Issue key\",\"Issue id\",\"Issue Type\",\"Status\",\n",
    "   \"Project key\",\"Project name\",\"Project type\",\"Project lead\",\n",
    "   \"Priority\",\"Resolution\",\"Assignee\",\"Creator\",\n",
    "   \"Created\",\"Updated\",\"Last Viewed\",\"Resolved\",\"Due Date\",\n",
    "   \"Description\",\"Environment\",\"Time Spent\",\"Work Ratio\",\"Σ Time Spent\",\"Security Level\"\n",
    "]\n",
    "print(\"Using DB:\", BRONZE_DB)\n",
    "print(\"Using file:\", file_path)\n",
    "# -----------------------\n",
    "# 1. Read CSV\n",
    "# -----------------------\n",
    "dbutils.fs.ls(file_path)\n",
    "raw = (\n",
    "   spark.read\n",
    "   .option(\"header\", True)\n",
    "   .option(\"inferSchema\", True)\n",
    "   .csv(file_path)\n",
    ")\n",
    "print(\"Original columns:\", len(raw.columns))\n",
    "# -----------------------\n",
    "# 2. Clean column names\n",
    "# -----------------------\n",
    "def clean_col(c):\n",
    "   c = c.strip().lower()\n",
    "   c = re.sub(r\"[^\\w]\", \"_\", c)\n",
    "   c = re.sub(r\"_+\", \"_\", c)\n",
    "   return c.strip(\"_\")\n",
    "raw_clean = raw.toDF(*[clean_col(c) for c in raw.columns])\n",
    "print(\"Cleaned columns:\", len(raw_clean.columns))\n",
    "# -----------------------\n",
    "# 3. Select only wanted columns\n",
    "# -----------------------\n",
    "def canon(s):\n",
    "   s = s.lower()\n",
    "   s = re.sub(r\"[^\\w]\", \"_\", s)\n",
    "   s = re.sub(r\"_+\", \"_\", s)\n",
    "   return s.strip(\"_\")\n",
    "wanted = [canon(c) for c in desired_cols]\n",
    "available = [c for c in wanted if c in raw_clean.columns]\n",
    "missing = [c for c in wanted if c not in raw_clean.columns]\n",
    "print(\"Selected columns:\", available)\n",
    "if missing:\n",
    "   print(\"Missing (ignored):\", missing)\n",
    "jira_df = raw_clean.select(*available)\n",
    "# -----------------------\n",
    "# 4. SAFE timestamp parsing (Jira formats)\n",
    "# -----------------------\n",
    "date_formats = [\n",
    "   \"dd/MMM/yyyy h:mm a\",\n",
    "   \"dd/MMM/yyyy hh:mm a\",\n",
    "   \"yyyy-MM-dd HH:mm:ss\"\n",
    "   \n",
    "]\n",
    "def parse_ts(colname):\n",
    "   exprs = [f\"try_to_timestamp(`{colname}`, '{fmt}')\" for fmt in date_formats]\n",
    "   return F.expr(\"coalesce(\" + \", \".join(exprs) + \")\")\n",
    "for c in [\"created\",\"updated\",\"resolved\",\"due_date\",\"last_viewed\"]:\n",
    "   if c in jira_df.columns:\n",
    "       jira_df = jira_df.withColumn(c, parse_ts(c))\n",
    "       print(f\"Parsed timestamp: {c}\")\n",
    "# -----------------------\n",
    "# 5. Save into slainte_bronze\n",
    "# -----------------------\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {BRONZE_DB}.{BRONZE_TABLE}\")\n",
    "(\n",
    "   jira_df\n",
    "   .write\n",
    "   .format(\"delta\")\n",
    "   .mode(\"overwrite\")\n",
    "   .saveAsTable(f\"{BRONZE_DB}.{BRONZE_TABLE}\")\n",
    ")\n",
    "# -----------------------\n",
    "# 6. Validation\n",
    "# -----------------------\n",
    "print(\"✅ Table saved:\", f\"{BRONZE_DB}.{BRONZE_TABLE}\")\n",
    "print(\"Row count:\", spark.table(f\"{BRONZE_DB}.{BRONZE_TABLE}\").count())\n",
    "spark.table(f\"{BRONZE_DB}.{BRONZE_TABLE}\").printSchema()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_jira_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
