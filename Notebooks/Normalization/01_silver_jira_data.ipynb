{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22c3ddc3-139f-48bb-af10-61f751d74a8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "BRONZE_DB = \"slainte_bronze\"\n",
    "SILVER_DB = \"slainte_silver\"\n",
    "JIRA_TABLE = f\"{BRONZE_DB}.jira_table\"\n",
    "SILVER_TABLE = \"jira_tickets_silver\"\n",
    "SILVER_QUAL = f\"{SILVER_DB}.{SILVER_TABLE}\"\n",
    "# =========================================================\n",
    "# LOAD BRONZE\n",
    "# =========================================================\n",
    "jira = spark.table(JIRA_TABLE)\n",
    "# =========================================================\n",
    "# BASE â€“ ONLY CLOSED TICKETS\n",
    "# =========================================================\n",
    "base = (\n",
    "   jira\n",
    "   .filter(F.lower(F.col(\"status\")).isin(\"closed\", \"done\", \"resolved\"))\n",
    "   .select(\n",
    "       F.col(\"issue_key\").cast(\"string\").alias(\"ticket_id\"),\n",
    "       F.col(\"status\").cast(\"string\").alias(\"status\"),\n",
    "       F.col(\"project_key\").cast(\"string\").alias(\"project_key\"),\n",
    "       F.col(\"description\").cast(\"string\").alias(\"ticket_description\")\n",
    "   )\n",
    ")\n",
    "# =========================================================\n",
    "# KEEP ONLY LATEST VERSION PER TICKET\n",
    "# =========================================================\n",
    "window_spec = Window.partitionBy(\"ticket_id\").orderBy(F.col(\"ticket_id\"))\n",
    "base = (\n",
    "   base\n",
    "   .withColumn(\"row_num\", F.row_number().over(window_spec))\n",
    "   .filter(F.col(\"row_num\") == 1)\n",
    "   .drop(\"row_num\")\n",
    ")\n",
    "# =========================================================\n",
    "# ðŸ”¥ BALANCED PRIORITY DISTRIBUTION (KEY CHANGE)\n",
    "# =========================================================\n",
    "base = base.withColumn(\n",
    "   \"priority\",\n",
    "   F.when(F.rand() < 0.20, \"High\")\n",
    "    .when(F.rand() < 0.60, \"Medium\")\n",
    "    .otherwise(\"Low\")\n",
    ")\n",
    "# =========================================================\n",
    "# SLA TARGETS\n",
    "# =========================================================\n",
    "base = base.withColumn(\n",
    "   \"resolution_target_hours\",\n",
    "   F.when(F.col(\"priority\") == \"High\", 4.0)\n",
    "    .when(F.col(\"priority\") == \"Medium\", 8.0)\n",
    "    .when(F.col(\"priority\") == \"Low\", 72.0)\n",
    ")\n",
    "# =========================================================\n",
    "# GENERATE LOGICAL CREATED / RESOLVED DATES\n",
    "# =========================================================\n",
    "# Created date: random in last 30 days\n",
    "base = base.withColumn(\n",
    "   \"created_at\",\n",
    "   F.current_timestamp() - F.expr(\"INTERVAL 1 DAY\") * F.floor(F.rand() * 30)\n",
    ")\n",
    "# Resolution logic:\n",
    "# 70% within SLA, 30% breached slightly\n",
    "base = base.withColumn(\n",
    "   \"resolution_hours\",\n",
    "   F.when(\n",
    "       F.rand() <= 0.7,\n",
    "       F.col(\"resolution_target_hours\") * (0.5 + F.rand() * 0.4)\n",
    "   ).otherwise(\n",
    "       F.col(\"resolution_target_hours\") * (1.1 + F.rand() * 0.5)\n",
    "   )\n",
    ")\n",
    "base = base.withColumn(\n",
    "   \"resolved_at\",\n",
    "   F.col(\"created_at\") + F.expr(\"INTERVAL 1 HOUR\") * F.col(\"resolution_hours\")\n",
    ")\n",
    "# =========================================================\n",
    "# SLA METRICS\n",
    "# =========================================================\n",
    "base = (\n",
    "   base\n",
    "   .withColumn(\"resolution_hours\", F.round(F.col(\"resolution_hours\"), 2))\n",
    "   .withColumn(\n",
    "       \"resolution_breach\",\n",
    "       F.col(\"resolution_hours\") > F.col(\"resolution_target_hours\")\n",
    "   )\n",
    "   .withColumn(\n",
    "       \"breach_hours\",\n",
    "       F.when(\n",
    "           F.col(\"resolution_hours\") > F.col(\"resolution_target_hours\"),\n",
    "           F.round(F.col(\"resolution_hours\") - F.col(\"resolution_target_hours\"), 2)\n",
    "       ).otherwise(0.0)\n",
    "   )\n",
    ")\n",
    "# =========================================================\n",
    "# ASSIGNEE â†’ RANDOM REAL PEOPLE\n",
    "# =========================================================\n",
    "people = [\"Ali Ben Salah\", \"Sarah Martin\", \"Youssef Trabelsi\", \"Emma Dubois\"]\n",
    "people_array = F.array(*[F.lit(p) for p in people])\n",
    "final_df = (\n",
    "   base\n",
    "   .withColumn(\n",
    "       \"assignee\",\n",
    "       people_array.getItem(F.floor(F.rand() * len(people)).cast(\"int\"))\n",
    "   )\n",
    "   .select(\n",
    "       \"ticket_id\",\n",
    "       \"priority\",\n",
    "       \"status\",\n",
    "       \"project_key\",\n",
    "       \"assignee\",\n",
    "       \"created_at\",\n",
    "       \"resolved_at\",\n",
    "       \"resolution_target_hours\",\n",
    "       \"resolution_hours\",\n",
    "       \"resolution_breach\",\n",
    "       \"breach_hours\",\n",
    "       \"ticket_description\"\n",
    "   )\n",
    ")\n",
    "# =========================================================\n",
    "# WRITE SILVER\n",
    "# =========================================================\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {SILVER_DB}\")\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {SILVER_QUAL}\")\n",
    "final_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(SILVER_QUAL)\n",
    "print(f\"âœ… FINAL JIRA SILVER TABLE CREATED: {SILVER_QUAL}\")\n",
    "print(\"Rows:\", spark.table(SILVER_QUAL).count())\n",
    "# =========================================================\n",
    "# QUICK VALIDATION\n",
    "# =========================================================\n",
    "spark.table(SILVER_QUAL).groupBy(\"priority\").count().show()\n",
    "spark.table(SILVER_QUAL).groupBy(\"resolution_breach\").count().show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8331538824390138,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_silver_jira_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
